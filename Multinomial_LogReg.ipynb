{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 1.6", 
            "name": "python3", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "# Multinomial Logistic Regression\n\nIn this script we use multinomial logistic regression to predict the handwritten digits of the MNIST dataset.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as imgplot\nimport numpy as np\n\n# To be compatible with python3\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n\nimport gzip\nimport time\nimport tensorflow as tf\nimport sys\n\nprint(sys.version_info)\nprint(tf.__version__)\n\nwith gzip.open('../data/mnist_4000.pkl.gz', 'rb') as f:\n    (X,y) = pickle.load(f, encoding='latin1')\nPIXELS = len(X[0,0,0,:])\nprint(X.shape, y.shape, PIXELS) #As read\nfig = plt.figure(figsize=(10,30))\nfor i in range(3):\n    a=fig.add_subplot(1,3,(i+1))\n    plt.imshow(-X[i,0,:,:], interpolation='none',cmap=plt.get_cmap('gray'))", 
            "metadata": {}, 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "sys.version_info(major=3, minor=5, micro=2, releaselevel='final', serial=0)\n0.12.1\n"
                }, 
                {
                    "ename": "FileNotFoundError", 
                    "output_type": "error", 
                    "evalue": "[Errno 2] No such file or directory: '../data/mnist_4000.pkl.gz'", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mFileNotFoundError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-1-572e888fc058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/mnist_4000.pkl.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mPIXELS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/conda3_runtime.v11/4.1.1/lib/python3.5/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/conda3_runtime.v11/4.1.1/lib/python3.5/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/mnist_4000.pkl.gz'"
                    ]
                }
            ]
        }, 
        {
            "source": "# We need to reshape for the logistic regression\nX = X.reshape([4000, 784])\nnp.shape(X)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Taken from http://stackoverflow.com/questions/29831489/numpy-1-hot-array\ndef convertToOneHot(vector, num_classes=None):\n    result = np.zeros((len(vector), num_classes), dtype='float32')\n    result[np.arange(len(vector)), vector] = 1\n    return result\nprint(\"class label\")\nprint(y[0:5])\nprint(\"class label in OneHot encodig\")\nprint(convertToOneHot(y[0:5], 10))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "### Construction of the graph", 
            "cell_type": "markdown"
        }, 
        {
            "source": "tf.reset_default_graph()\ntf.set_random_seed(1)\n#Note that we usually do not like to specify the batchsize. Choosing it `None` will leave it open\nx = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\ny_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')\n\n# We start with random weights a\nw = tf.Variable(tf.random_normal([784, 10], stddev=0.01))\nb = tf.Variable(tf.zeros([10]))\n\n#<-------------------------- Your code here ---------------\n# Your code here, do a matrix multiplication between x,w and an addtion of b\nz = \n# End of your code\n\nprob = tf.nn.softmax(z)\ninit_op = tf.global_variables_initializer() ", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "### Store the graph and visualize it in tensorboard", 
            "cell_type": "markdown"
        }, 
        {
            "source": "tf.summary.FileWriter(\"/tmp/dumm/mlp_tensorflow_solution/\", tf.get_default_graph()).close() #<--- Where to store", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "### Doing a forward pass of the untrained network", 
            "cell_type": "markdown"
        }, 
        {
            "source": "with tf.Session() as sess:\n    sess.run(init_op)\n    res_val = sess.run(prob, feed_dict={x:X[0:10]})\nprint(\"true label = \",y[0])\nprint()\nprint(\"probability for each class = \",res_val[0])\nprint()\nprint(\"pred label = \",np.argmax(res_val[0]))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "### Train the model", 
            "cell_type": "markdown"
        }, 
        {
            "source": "loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(prob), reduction_indices=[1]))\n\n#train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\ntrain_op = tf.train.AdagradOptimizer(0.1).minimize(loss)\ninit_op = tf.global_variables_initializer() \nwith tf.Session() as sess:\n    sess.run(init_op)\n    for i in range(1000):\n        idx = np.random.permutation(2400)[0:128] #Easy minibatch of size 128\n        #res, out_val, _ = sess.run((loss, prob, train_op),feed_dict={x:X[idx], y_true:convertToOneHot(y[idx], 10)})\n        loss_, out_val, _ = sess.run((loss, prob, train_op),feed_dict={x:X[idx], y_true:convertToOneHot(y[idx], 10)})\n        if (i % 100 == 0):\n            print(loss_)\n    \n    # Get the loss for the validation results (from 2400:3000)\n    print('Loss for the validation set')\n    #<-------------------------- Your code here ---------------\n    loss_val = sess.run()#get loss here\n    print(loss_val)\n    # Get the results for the validation set\n    res_val = sess.run()#get probs here\n    #<-------------------------  End of your code here --------", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# and estimate the preformance on the validation set\n# Your code here\nprint(\"Accuracy =\",np.mean(np.argmax(res_val, axis = 1) == y[2400:3000]))\nimport random \nrmd=random.randint(2400,3000)\nprint(\"probs =\",np.round(res_val[rmd-2400],2))\nprint(\"predicted label =\",np.argmax(res_val[rmd-2400]))\nprint(\"true label =\",np.round(y[rmd],2))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}